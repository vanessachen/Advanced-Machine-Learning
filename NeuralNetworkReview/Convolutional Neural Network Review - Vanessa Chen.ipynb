{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "1. Type `python3` into Terminal. If you see a few lines of text followed by `>>>`, then Python3 is already installed. Type Ctrl+d (or close the window) to exit and skip to step 3.\n",
    "2. Go to https://www.python.org/downloads/ and click on \"Download Python 3.6.4\". Run the installer and follow the directions. Repeat step 1 to make sure it has successfully installed.\n",
    "3. Install jupyter notebook, so that you can use this tutorial, by typing the following into Terminal:\n",
    "    `pip3 install jupyter`\n",
    "4. Start the jupyter notebook by typing in Terminal _in the same folder that you have this file_ \n",
    "    `jupyter notebook`\n",
    "    This should open a tab in your web browser with a list of files in the folder. Click on this ipynb file to open it.\n",
    "3. Install the tensorflow machine learning library by typing the following into Terminal:\n",
    "    `pip3 install --upgrade tensorflow`\n",
    "4. Install the keras machine learning library by typing the following into Terminal:\n",
    "    `pip3 install keras`\n",
    "5. Install the libraries we'll need to display the images: `pip3 install numpy matplotlib`\n",
    "6. Test that the keras install worked: Again, type `python3` into the Terminal. When the `>>>` prompt comes up, type `from keras.models import Sequential`. If you don't get any error output, then it worked. Type Ctrl+d (or close the window) to exit.\n",
    "    * If you get an error like `ModuleNotFoundError: No module named 'theano'` then you need to switch the backend to tensorflow. See the instructions at https://keras.io/backend/ or ask me for help.\n",
    "    * If you get a warning like `/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6` you can ignore it. This is a known (trivial) issue with Tensorflow 1.4 for OSX. See https://github.com/tensorflow/tensorflow/issues/14182 if you'd like more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Code\n",
    "\n",
    "First, we'll want to import the keras modules we'll be using for our neural network and the numpy and matplotlib modules that we'll be using for displaying our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "import numpy\n",
    "from matplotlib.pyplot import imshow\n",
    "# tell matplotlib to display images within this notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The First Model\n",
    "\n",
    "Next, let's set up the structure of our model. We'll start with a really simple model, with just one convolutional layer that has just one filter. We are going to be using 9x9-pixel grayscale images, so we set the input shape accordingly. If we were using color images with red-green-blue channels, the last dimension (of input_shape) would be size three (one for each color) instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_size = 3 #the number of terms \n",
    "image_size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model0 = Sequential()\n",
    "model0.add(Conv2D(filters=1,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=1,\n",
    "                  input_shape=(image_size, image_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally at this point, we would compile and train (aka fit) our model, but instead we're going to set the weights manually and then see the output we get on some test images.\n",
    "\n",
    "First, let's take a look at what the randomly generated weights look like, to understand the format that we'll need to use to set the new weights. By changing the parameters of the model above and looking at how it affects the weight structure, we can understand what each weight is connected to (try it!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-0.3462083 ]],\n",
       " \n",
       "         [[-0.06585187]],\n",
       " \n",
       "         [[ 0.3135904 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.38894275]],\n",
       " \n",
       "         [[ 0.48490715]],\n",
       " \n",
       "         [[ 0.3636008 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.5594405 ]],\n",
       " \n",
       "         [[ 0.0707854 ]],\n",
       " \n",
       "         [[ 0.19883072]]]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model0.get_weights()\n",
    "weights \n",
    "#this is set up in the format where the entire array below is one layer\n",
    "#the layer currently has a kernal size of 3, so each grouped y-value has 3 corresponding x-values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we change the weights so that the filter will capture a certain pattern. We'll explore more about what this means below, but feel free to start generating some guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1.]],\n",
       " \n",
       "         [[ 1.]],\n",
       " \n",
       "         [[ 1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_num = 0 #set to 0 because there is only 1 layer \n",
    "filter_num = 0 #set to 0 because there is only 1 filter\n",
    "#set the weights of the first kernal to 1, and the last two to -1\n",
    "#default Keras stride = 1\n",
    "y = 0\n",
    "for x in range(kernel_size):\n",
    "    weights[layer_num][y][x][0][filter_num] = 1\n",
    "for y in range(1,kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        weights[layer_num][y][x][0][filter_num] = -1\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save those weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model0.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Images\n",
    "\n",
    "Now, let's create some 9x9 images that we will run through our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1142073c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113f57978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#each number here corresponds to a grayscale color\n",
    "image0 = numpy.array([\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image0, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1143480f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUXCgMAoOFEbBgcIoOFDY7wBzR/h2oZ1CRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113f93cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image1 = numpy.array([\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image1, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Images Through Model\n",
    "\n",
    "The images need to be in a slightly different format for Keras than they do for the imshow command. Right now, they are 9x9 arrays, and we need them to be 9x9x1 -- three dimensional instead of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in [image0]: # look at this one image at a time to see the pattern easier \n",
    "    images.append(numpy.resize(image, (image_size, image_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we give these images to our model and take a look at what the filter has found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.predict(numpy.array(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions -- Answer these before going on to the second model!\n",
    "1. There are a lot of numbers in the output above. Where is each one coming from? Why are they in groups of seven?\n",
    "\n",
    "###### Because the 3x3 kernal goes through each section of the 9x9 image, and multiplies those grayscale values by the weights defined, the prediction returns a 7x7 array. Because the weights are set so that the first row is '1' while the last 2 rows are '-1' the model seems to look for sections of light colors, followed by darker colors. Thus, when a particular number is greater than 0, that represents a 3x3 section of the image that has a row of light colors followed by 2 darker colors. \n",
    "\n",
    "### Question 2\n",
    "In which image is the filter \"finding\" something, and why does this make sense, given the pattern of weights that was set?\n",
    "\n",
    "##### As explained in the response to the previous question, because the filter is looking for a 3x3 section of a light colored row followed by two darker colored rows, the model does not seem to find anything for Image0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Second Model\n",
    "\n",
    "Let's move to a slightly more complex model. Now, there are two convolutional layers, the first with two filters and the second with one filter. One other difference is that we're going to be taking strides so that we only examine each pixel once, instead of looking at overlapping groups. This makes it a little simpler to set the manual weights correctly for the pattern I chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Sequential() #Keras sequential model API\n",
    "model1.add(Conv2D(filters=2, kernel_size=kernel_size, input_shape=(image_size, image_size, 1), strides=(3,3))) #strides to prevent overlap\n",
    "model1.add(Conv2D(filters=1, kernel_size=kernel_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a different model structure, we will have a different number of weights to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-0.15816331, -0.4242195 ]],\n",
       " \n",
       "         [[ 0.15062562,  0.06367734]],\n",
       " \n",
       "         [[-0.42442483, -0.42404205]]],\n",
       " \n",
       " \n",
       "        [[[-0.22347866, -0.3833078 ]],\n",
       " \n",
       "         [[-0.39482662, -0.41895846]],\n",
       " \n",
       "         [[-0.16151056, -0.02436706]]],\n",
       " \n",
       " \n",
       "        [[[-0.24158405, -0.33968347]],\n",
       " \n",
       "         [[-0.39524448, -0.4626074 ]],\n",
       " \n",
       "         [[ 0.09279177,  0.325713  ]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 0.19147435],\n",
       "          [-0.14828947]],\n",
       " \n",
       "         [[ 0.3699647 ],\n",
       "          [ 0.00091654]],\n",
       " \n",
       "         [[ 0.07361099],\n",
       "          [ 0.20370874]]],\n",
       " \n",
       " \n",
       "        [[[-0.2183109 ],\n",
       "          [ 0.18670705]],\n",
       " \n",
       "         [[ 0.25429878],\n",
       "          [ 0.05717179]],\n",
       " \n",
       "         [[-0.32516518],\n",
       "          [-0.3558999 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.401034  ],\n",
       "          [ 0.45963982]],\n",
       " \n",
       "         [[ 0.23103598],\n",
       "          [ 0.06744811]],\n",
       " \n",
       "         [[ 0.035557  ],\n",
       "          [ 0.28745565]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model1.get_weights()\n",
    "weights \n",
    "#size of weights array = based on kernal size \n",
    "#first array includes weights for filter 1, weights for filter 2\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we manually set the weights to match some specific patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0 #first filter\n",
    "for y in range(kernel_size):#kernel currently 3\n",
    "    for x in range(kernel_size):\n",
    "        if y == x: #right diagonal starting from top left corner to bottom right\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else: # positive for finding pattern, negative for not pattern\n",
    "            weights[layer_num][y][x][0][filter_num] = -1\n",
    "\n",
    "filter_num = 1 #second filter\n",
    "for y in range(kernel_size):#kernal_size = 3\n",
    "    for x in range(kernel_size):\n",
    "        if kernel_size - 1 - y == x: #y=-x+2 for kernal=3; pattern = diagonal from bottom left to top right\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the first layer has a stride of 3x3, then after the input runs through the first layer, the output is a 3x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 2 #2nd Convolutional layer\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        input_filter_num = 0\n",
    "        if y == x: #same pattern for first filter of layer 1\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25 #-0.25 because it needs to find the pattern\n",
    "        input_filter_num = 1 #set to second filter\n",
    "        if kernel_size - 1 - y == x: #same pattern for second filter of layer 1\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the input to the second layer is 3x3, the output is just 1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1., -1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[-1.,  1.]]],\n",
       " \n",
       " \n",
       "        [[[-1., -1.]],\n",
       " \n",
       "         [[ 1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[ 1., -1.]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 1.  ],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [ 1.  ]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [-0.25]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, run our test images through the model to see what the filters output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_images(images):\n",
    "    resized_images = []\n",
    "    for image in images:#have to resize the image b/c Keras wants 9x9x1 array (3D) instead of 9x9\n",
    "        resized_images.append(numpy.resize(image, (image_size, image_size, 1))) \n",
    "    return model1.predict(numpy.array(resized_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1150.]]],\n",
       "\n",
       "\n",
       "       [[[-1150.]]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#should expect a 1x1 prediction\n",
    "predict_images([image0,image1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Note above that neither image0 nor image1 gets a positive output. Create some images that do get positive ouputs from this model. The code below might help you get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x114c99b70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+bQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114acf6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_black = numpy.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_black, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x114d8cf98>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114c3fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_white = numpy.array([\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_white, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[    0.]]],\n",
       "\n",
       "\n",
       "       [[[-2295.]]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image_black, image_white])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the black image would return a 0, while the white image would return a large negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1150c4a90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114f1f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_black_diagonals = numpy.array([\n",
    "    [0, 255, 255, 255, 255, 0, 0, 255, 255],\n",
    "    [255, 0, 255, 255, 0, 255, 255, 0, 255],\n",
    "    [255, 255, 0, 0, 255, 255, 255, 255, 0],\n",
    "    [255, 255, 0, 0, 255, 255, 255, 255, 0],\n",
    "    [255, 0, 255, 255, 0, 255, 255, 0, 255],\n",
    "    [0, 255, 255, 255, 255, 0, 0, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_black_diagonals, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115694278>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1155ba278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_white_diagonals = numpy.array([\n",
    "    [255, 0, 0, 0, 0, 255, 255, 0, 0],\n",
    "    [0, 255, 0, 0, 255, 0, 0, 255, 0],\n",
    "    [0, 0, 255, 255, 0, 0, 0, 0, 255],\n",
    "    [0, 0, 255, 255, 0, 0, 0, 0, 255],\n",
    "    [0, 255, 0, 0, 255, 0, 0, 255, 0],\n",
    "    [255, 0, 0, 0, 0, 255, 255, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_white_diagonals, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-2805.]]],\n",
       "\n",
       "\n",
       "       [[[  510.]]]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image_black_diagonals, image_white_diagonals])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 (Optional)\n",
    "\n",
    "Add additional filters to the model, and create images that get positive weights for different patterns of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
